# üìä Olist E-Commerce Analytics Dashboard

Este projeto √© uma solu√ß√£o completa de Business Intelligence (BI) para an√°lise de dados do E-commerce Olist. A aplica√ß√£o foi constru√≠da utilizando **Python**, **Streamlit** e **PostgreSQL** (via Supabase), seguindo uma arquitetura modular para garantir escalabilidade e f√°cil manuten√ß√£o.

## üèóÔ∏è Arquitetura e Design Patterns

O projeto adota uma **Arquitetura em Camadas (Layered Architecture)**, separando claramente as responsabilidades de extra√ß√£o de dados, regras de neg√≥cio e interface do usu√°rio. Essa abordagem facilita a manuten√ß√£o e permite que diferentes partes do sistema evoluam independentemente.

### Estrutura Modular 

* **ETL Layer (`etl/`)**: Respons√°vel pela conex√£o com o banco de dados (Repository Pattern), execu√ß√£o de queries SQL e limpeza inicial dos dados. Nenhuma l√≥gica visual reside aqui.
* **UI Layer (`ui/`)**: Cont√©m componentes visuais, gr√°ficos (Plotly) e estilos CSS. Esta camada √© "burra", apenas recebe dados e os desenha.
* **Orchestrator (`app.py`)**: O ponto de entrada. Ele solicita os dados ao ETL, aplica filtros de usu√°rio e decide qual componente da UI deve ser renderizado.

```mermaid
graph TD
    subgraph "Data Source (Local)"
        RAW[db.Olist / CSVs]
    end

    subgraph "ETL Pipeline"
        PY[upload_olist.py]
    end

    subgraph "Data Warehouse (Cloud)"
        DW[(Supabase PostgreSQL)]
    end

    subgraph "Application Layer"
        APP[app.py - Controller]
        ETL[etl/ - Repository]
        UI[ui/ - Visual Components]
    end

    subgraph "User Interface"
        ST[Streamlit Dashboard]
    end

    RAW --> PY
    PY -->|Upload| DW
    DW -->|Query| ETL
    ETL -->|Dataframes| APP
    APP -->|Processamento| UI
    UI -->|Renderiza√ß√£o| ST
```

## üìÇ Estrutura de pastas

```text
Olist-Analytics/
‚îú‚îÄ‚îÄ database/
‚îÇ   ‚îú‚îÄ‚îÄ db.Olist                 # Fonte de dados bruta (SQLite ou Arquivos)
‚îÇ   ‚îî‚îÄ‚îÄ pipelines/
‚îÇ       ‚îî‚îÄ‚îÄ upload_olist.py      # Script de carga para o Data Warehouse
‚îú‚îÄ‚îÄ etl/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ database.py              # Gerenciador de conex√£o SQLAlchemy
‚îÇ   ‚îú‚îÄ‚îÄ repository.py            # Queries e acesso a dados
‚îÇ   ‚îî‚îÄ‚îÄ utils.py                 # Fun√ß√µes auxiliares
‚îú‚îÄ‚îÄ ui/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ charts.py                # Gera√ß√£o de gr√°ficos Plotly
‚îÇ   ‚îú‚îÄ‚îÄ maps.py                  # Mapas coropl√©ticos
‚îÇ   ‚îú‚îÄ‚îÄ components.py            # Cards e KPIs
‚îÇ   ‚îî‚îÄ‚îÄ styles.py                # CSS customizado
‚îú‚îÄ‚îÄ .env                         # Vari√°veis de ambiente (N√ÉO COMITAR)
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ app.py                       # Orquestrador da aplica√ß√£o
‚îú‚îÄ‚îÄ requirements.txt             # Depend√™ncias
‚îî‚îÄ‚îÄ README.md
```

## üöÄ Como Rodar o Projeto

Siga o passo a passo abaixo para configurar o ambiente do zero.

Pr√©-requisitos:

* Python 3.10+
* Git
* Conta no [Supabase](https://supabase.com/) (ou qualquer banco PostgreSQL).

### 1.üì• Obtendo os Dados

Este projeto utiliza o Brazilian E-Commerce Public Dataset by Olist.

    Baixe os dados oficiais no Kaggle  - https://www.kaggle.com/datasets/olistbr/brazilian-ecommerce

    Extraia os arquivos CSV.

    Coloque-os dentro da pasta database/.


### 2. Configurando o Data Warehouse (Supabase)

1.  Crie um novo projeto no Supabase.
2.  V√° em **Project Settings** > **Database** > **Connection string**.
3.  Copie a URL de conex√£o (selecione a op√ß√£o "URI").
4.  A string ter√° este formato: `postgresql://postgres:[SUA-SENHA]@[HOST]:5432/postgres`

### 3. Configura√ß√£o do Ambiente Local

Clone o reposit√≥rio e navegue at√© a pasta:

```bash
git clone https://github.com/RafaelRodrigues44/olist-analytics.git
cd olist-analytics
```

Crie e ative o ambiente virtual (`.venv`):

**Para Windows:**
```bash
python -m venv .venv
.venv\Scripts\activate
```

**Para Linux/Mac:**
```bash
python3 -m venv .venv
source .venv/bin/activate
```

Instale as depend√™ncias:
```bash
pip install -r requirements.txt
```

### 4. Configurando Vari√°veis de Ambiente (.env)

Crie um arquivo chamado `.env` na raiz do projeto. Este arquivo guardar√° suas credenciais de forma segura.

**Conte√∫do do `.env`:**

```ini
# Exemplo de configura√ß√£o (Aten√ß√£o: Caracteres especiais na senha devem ser URL Encoded)
# Se sua senha tem '@', use '%40'. Se tem '#', use '%23'.

DATABASE_URL="postgresql://postgres:SuaSenhaSegura%40123@db.pvmcbtkbsyzqyyrvkbxa.supabase.co:5432/postgres"
```

> **Nota de Seguran√ßa:** O arquivo `.env` j√° est√° no `.gitignore` para evitar que suas senhas subam para o GitHub.

### 5. Executando o Pipeline de Dados (ETL)

Antes de abrir o dashboard, precisamos enviar os dados locais (`database/db.Olist`) para a nuvem (Supabase).

Execute o script de pipeline:

```bash
python database/pipelines/upload_olist.py
```

*Este script ir√° ler os dados locais, conectar no Supabase usando a `DATABASE_URL` do `.env` e criar as tabelas necess√°rias.*

### 6. Executando o Dashboard

Com o banco de dados populado, inicie a aplica√ß√£o Streamlit:

```bash
streamlit run app.py
```

O dashboard abrir√° automaticamente no seu navegador em `http://localhost:8501`.

## üõ†Ô∏è Tecnologias Utilizadas

* **Linguagem:** Python 3.14
* **Frontend:** Streamlit
* **Visualiza√ß√£o:** Plotly Express
* **Banco de Dados:** PostgreSQL (Supabase)
* **ORM/Conex√£o:** SQLAlchemy & Pandas
* **Design:** CSS Customizado & Layout Responsivo

## üìû Contato

Rafael - https://www.linkedin.com/in/rafael-rodrigues-ab2a981b5/ - rafael.rodrigues85@hotmail.com

*Desenvolvido como parte do portf√≥lio de Engenharia de Dados e Fullstack Development.*